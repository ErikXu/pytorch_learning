{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_templates = [\n",
    "    \"https://club.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98&productId=100007218425&score={}&sortType=5&page={}&pageSize=10&isShadowSku=0&fold=1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(url):\n",
    "    comments = []\n",
    "    \n",
    "    rsp = requests.get(url)\n",
    "    rsp.encoding = \"gbk\"\n",
    "    \n",
    "    if rsp.status_code != 200:\n",
    "        return []\n",
    "    \n",
    "    content = rsp.text\n",
    "    if content:\n",
    "        ind = content.find(\"(\")\n",
    "        s1 = content[ind+1:-2]\n",
    "        #print(s1)\n",
    "        try:\n",
    "            js = json.loads(s1)\n",
    "            comment_infos = js[\"comments\"]\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "            return ([])\n",
    "        \n",
    "        for comment_info in comment_infos:\n",
    "            comment_content = comment_info[\"content\"]\n",
    "            str1 = comment_content + \"\\n\"\n",
    "            comments.append(str1)\n",
    "            \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_comments = []\n",
    "j = 0\n",
    "\n",
    "for template in url_templates:\n",
    "    for i in range(100):\n",
    "        url = template.format(3, i)\n",
    "        good_comments += get_comments(url)\n",
    "        time.sleep(1)\n",
    "        print(\"第{}条记录，文本总长度{}\".format(j, len(good_comments)))\n",
    "        j +=1\n",
    "\n",
    "fw = open(\"good.txt\", \"w\", encoding=\"utf-8\")\n",
    "fw.writelines(good_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_comments = []\n",
    "j = 0\n",
    "\n",
    "for template in url_templates:\n",
    "    for i in range(100):\n",
    "        url = template.format(1, i)\n",
    "        bad_comments += get_comments(url)\n",
    "        time.sleep(1)\n",
    "        print(\"第{}条记录，文本总长度{}\".format(j, len(bad_comments)))\n",
    "        j +=1\n",
    "\n",
    "fw = open(\"bad.txt\", \"w\", encoding=\"utf-8\")\n",
    "fw.writelines(bad_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_punc(sentence):\n",
    "    sentence = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\'“”《》?“]+|[+——！，。？、~@#￥%……&*（）：]+\", \"\", sentence)  \n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(good_file, bad_file, is_filter = True):\n",
    "    all_words = []\n",
    "    pos_sentences = []\n",
    "    neg_sentences = []\n",
    "    with open(good_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "        for idx, line in enumerate(fr):\n",
    "            if is_filter:\n",
    "                line = filter_punc(line)\n",
    "            words = jieba.lcut(line)\n",
    "            if len(words) > 0:\n",
    "                all_words += words\n",
    "                pos_sentences.append(words)\n",
    "    print(\"{0} 包含 {1} 行, {2} 个词.\".format(good_file, idx+1, len(all_words)))\n",
    "\n",
    "    count = len(all_words)\n",
    "    with open(bad_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "        for idx, line in enumerate(fr):\n",
    "            if is_filter:\n",
    "                line = filter_punc(line)\n",
    "            words = jieba.lcut(line)\n",
    "            if len(words) > 0:\n",
    "                all_words += words\n",
    "                neg_sentences.append(words)\n",
    "    print(\"{0} 包含 {1} 行, {2} 个词.\".format(bad_file, idx+1, len(all_words)-count))\n",
    "\n",
    "    dic = {}\n",
    "    cnt = Counter(all_words)\n",
    "    for word, freq in cnt.items():\n",
    "        dic[word] = [len(dic), freq]\n",
    "    print('字典大小：{}'.format(len(dic)))\n",
    "    return(pos_sentences, neg_sentences, dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2index(word, diction):\n",
    "    if word in diction:\n",
    "        value = diction[word][0]\n",
    "    else:\n",
    "        value = -1\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2word(index, diction):\n",
    "    for w,v in diction.items():\n",
    "        if v[0] == index:\n",
    "            return(w)\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Erik\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.917 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good.txt 包含 3309 行, 61497 个词.\n",
      "bad.txt 包含 1354 行, 18912 个词.\n",
      "字典大小：7213\n"
     ]
    }
   ],
   "source": [
    "good_file = \"good.txt\"\n",
    "bad_file  = \"bad.txt\"\n",
    "\n",
    "pos_sentences, neg_sentences, diction = prepare_data(good_file, bad_file, True)\n",
    "st = sorted([(v[1], w) for w, v in diction.items()])\n",
    "#print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(sentence, dictionary):\n",
    "    vector = np.zeros(len(dictionary))\n",
    "    for l in sentence:\n",
    "        vector[l] += 1\n",
    "    return(1.0 * vector / len(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
